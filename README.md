# Optimize Machine Learning algorithms on /Womens Clothing E-Commerce dataset

Optimization algorithms play a crucial role in machine learning, directly impacting model performance, training efficiency, and convergence speed. This project aims to compare three widely used optimization techniques—Gradient Descent (GD), Stochastic Gradient Descent (SGD), and Adam (Adaptive Moment Estimation)—to analyze their differences in terms of computational efficiency, learning behavior, and overall effectiveness in minimizing loss functions.

